{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCIITFHZ79Vw"
      },
      "source": [
        "# UCS2612 Machine Learning Laboratory\n",
        "## A8 â€“ Applications of Random Forest and AdaBoost Ensemble Techniques\n",
        "\n",
        "**Name:** Rakshith\n",
        "\n",
        "**Reg No:** 3122215001078\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXzV5iOTOuRh"
      },
      "source": [
        "## 1. Loading the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amF0Vm_D79V2"
      },
      "source": [
        "- The dataset is imported using the `fetch_ucirepo` function from the `ucimlrepo` library.\n",
        "- The features and target labels are extracted from the dataset and stored in separate variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzeueQ_dMDnM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "b890d43e-1058-43f3-9354-219200139629"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ucimlrepo'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cd1334aa301f>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaggingClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mucimlrepo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_ucirepo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Task 1: Loading the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ucimlrepo'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# Task 1: Loading the dataset\n",
        "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
        "\n",
        "# Extract features and target variable\n",
        "X = breast_cancer_wisconsin_diagnostic.data.features\n",
        "y = breast_cancer_wisconsin_diagnostic.data.targets\n",
        "column_names = list(breast_cancer_wisconsin_diagnostic.data.features.columns)\n",
        "target_column_name=list(breast_cancer_wisconsin_diagnostic.data.targets.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bIKdzEtMDnQ"
      },
      "outputs": [],
      "source": [
        "# Display features and targets\n",
        "print(\"Features:\")\n",
        "print(X.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIZ10NkbMDnR"
      },
      "outputs": [],
      "source": [
        "print(\"Targets:\")\n",
        "print(y.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rn1zTFvO0gb"
      },
      "source": [
        "## 2. Pre-processing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOq7wuJ-79WA"
      },
      "source": [
        "- The dataset is checked for missing values to ensure data completeness.\n",
        "- Since there are no missing values in the dataset, no imputation or replacement of missing values is performed.\n",
        "- Non-numeric columns in the dataset are encoded into numeric values using label encoding.\n",
        "- Numeric features in the dataset are standardized using `StandardScaler` to have a mean of 0 and a standard deviation of 1.\n",
        "- Numeric features in the dataset are normalized using `MinMaxScaler` to scale each feature to a specified range.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqV6AVZb79WA"
      },
      "source": [
        "### Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PiM0-50MDnS"
      },
      "outputs": [],
      "source": [
        "# Check for missing values in the DataFrame\n",
        "missing_values = X.isnull().sum()\n",
        "\n",
        "# Check if there are any missing values in each column\n",
        "columns_with_missing_values = missing_values[missing_values > 0]\n",
        "\n",
        "if columns_with_missing_values.empty:\n",
        "    print(\"No missing values in the DataFrame\")\n",
        "else:\n",
        "    print(\"Columns with missing values:\")\n",
        "    print(columns_with_missing_values)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHLNJ-Hn79WB"
      },
      "source": [
        "### Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOmKceKQ79WC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Encoding non-numeric columns\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = pd.DataFrame(y, columns=target_column_name)\n",
        "X = pd.DataFrame(X, columns=column_names)\n",
        "X = X.apply(label_encoder.fit_transform)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuGgERrSMDnS"
      },
      "outputs": [],
      "source": [
        "print(\"Features after Handling Missing Values & Encoding:\")\n",
        "print(X.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_U-9rHCMMDnS"
      },
      "outputs": [],
      "source": [
        "print(\"Target after encoding\")\n",
        "print(y.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMVJkKXB79WE"
      },
      "source": [
        "### Standardization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhZ3Nj4XMDnT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X=pd.DataFrame(X, columns=column_names)\n",
        "print(\"DataFrame Head after Standardization:\")\n",
        "print(X.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CwsANwt79WF"
      },
      "source": [
        "### Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gi_JALM379WF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Normalization\n",
        "minmax_scaler = MinMaxScaler()\n",
        "X = minmax_scaler.fit_transform(X)\n",
        "X=pd.DataFrame(X, columns=column_names)\n",
        "print(\"DataFrame Head after Normalization:\")\n",
        "print(X.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oJVSt0-79WG"
      },
      "source": [
        "## 3. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9smnaU679WG"
      },
      "source": [
        "- Visualization techniques such as pie charts are used to visualize the distribution of categorical variables, such as the target variable.\n",
        "- Scatter plots are utilized to explore relationships between pairs of numeric features, allowing for the identification of potential correlations or patterns.\n",
        "- Heatmaps are generated to visualize the correlation matrix between features, providing insights into the strength and direction of relationships among variables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKTwpSCo79WG"
      },
      "source": [
        "### Pie-Chart for target Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNPjnJqtMDnT"
      },
      "outputs": [],
      "source": [
        "# Pie chart for target variable\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "y_labels = label_encoder.inverse_transform([0, 1])\n",
        "y_1d = y.squeeze()  # Convert y to 1D array\n",
        "plt.pie(np.bincount(y_1d), labels=['Benign', 'Malignant'], autopct='%1.1f%%', colors=['skyblue', 'lightcoral'])\n",
        "plt.title('Distribution of Diagnosis')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BIUCemNQE5uQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U34aC4gG79WH"
      },
      "source": [
        "### Pairwise scatter plot for first 5 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FZ8Ftv6MDnT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Pairwise scatter plot for first 5 features\n",
        "sns.pairplot(X.iloc[:, :5], diag_kind='kde')\n",
        "plt.suptitle('Pairwise Scatter Plot for First 5 Features', y=1.02)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5XziEs879WI"
      },
      "source": [
        "### Correlation heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FSVIRRuMDnU"
      },
      "outputs": [],
      "source": [
        "# Correlation heatmap\n",
        "plt.figure(figsize=(21, 18))\n",
        "correlation_matrix = X.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPnnqKdD79WJ"
      },
      "source": [
        "## 4. Feature Engineering Techniques (Selecting best k features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iGS2j_O79WK"
      },
      "source": [
        "- Feature engineering techniques are applied to select the most relevant features for modeling.\n",
        "- The `SelectKBest` method from scikit-learn's `feature_selection` module is used to select the top k features based on their scores computed using the ANOVA F-value (`f_classif`) metric.\n",
        "- In this example, 20 top features are selected using the `SelectKBest` method and transformed accordingly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaYc4MmeMDnU"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Using SelectKBest for feature selection\n",
        "k = 20  # Number of top features to select\n",
        "selector = SelectKBest(score_func=f_classif, k=k)\n",
        "X= selector.fit_transform(X, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULAc3Z2k79WK"
      },
      "source": [
        "## 5. Split the data into training, testing and validation sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXb-QQrE79WL"
      },
      "source": [
        "- The dataset is split into training and testing sets using the `train_test_split` function to evaluate model performance on unseen data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0isoVMzMDnU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Task 5: Split the data into training, testing, and validation sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQwRm_JD79WS"
      },
      "source": [
        "## 6. Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAMFxwJc79WS"
      },
      "source": [
        "- Ensemble models such as Bagging, Random Forest, and AdaBoost are trained on the training data using scikit-learn's implementation of these algorithms.\n",
        "- Each ensemble model learns to predict the target labels based on the input features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JL__QGnqMDnU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Task 6: Train the model\n",
        "# Ensemble Models: Bagging, Random Forest, AdaBoost\n",
        "bagging_clf = BaggingClassifier(random_state=40)\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "rf_clf = RandomForestClassifier(random_state=40)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "adaboost_clf = AdaBoostClassifier(random_state=40)\n",
        "adaboost_clf.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6IXQvIu79WV"
      },
      "source": [
        "## 7. Test the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6XySbOs79WW"
      },
      "source": [
        "- The trained models are used to make predictions on the test data to evaluate their performance.\n",
        "- The predictions are compared to the true labels to assess the accuracy and effectiveness of the models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48Ewa8OrMDnV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Task 7: Test the model\n",
        "y_pred_bagging = bagging_clf.predict(X_test)\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "y_pred_adaboost = adaboost_clf.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VlsATTL79Wb"
      },
      "source": [
        "## 8. Measure the performance of the trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUcSofiV79Wo"
      },
      "source": [
        "- The accuracy of each ensemble model is calculated using scikit-learn's `accuracy_score` function.\n",
        "- The accuracy metric quantifies the proportion of correctly classified instances in the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5I763CeMDnV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Task 8: Measure the performance of the trained model\n",
        "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "accuracy_adaboost = accuracy_score(y_test, y_pred_adaboost)\n",
        "print(\"#########ACCURACY#########\")\n",
        "print(f\"Bagging: {accuracy_bagging}\")\n",
        "print(f\"Random Forest: {accuracy_rf}\")\n",
        "print(f\"AdaBoost: {accuracy_adaboost}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUwA4jkO79W9"
      },
      "source": [
        "## 9. Compare the results of each ensemble model using graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JPkvlva79W9"
      },
      "source": [
        "- Graphs such as bar plots or box plots can be used to compare the performance metrics (e.g., accuracy) of different ensemble models.\n",
        "- Another visualization technique, like confusion matrices or precision-recall curves, can provide insights into the models' strengths and weaknesses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8yIXaC-MDnV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Task 9: Compare the results of each ensemble model using graphs\n",
        "# Bar plot for accuracy comparison\n",
        "models = ['Bagging', 'Random Forest', 'AdaBoost']\n",
        "accuracies = [accuracy_bagging, accuracy_rf, accuracy_adaboost]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(models, accuracies, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
        "plt.xlabel('Ensemble Models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy Comparison of Ensemble Models')\n",
        "plt.ylim(0.9, 1.0)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thWAuFcX79W_"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9AdaF7079XB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot confusion matrix for each model\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, (clf, name) in enumerate([(bagging_clf, 'Bagging'), (rf_clf, 'Random Forest'), (adaboost_clf, 'AdaBoost')], 1):\n",
        "    plt.subplot(1, 3, i)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "                xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])\n",
        "    plt.title(f'Confusion Matrix - {name}')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.ylabel('True label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIFolbkc79XC"
      },
      "source": [
        "## 10. Represent the ROC of training and test results in the graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O6u4mSr79XD"
      },
      "source": [
        "- Receiver Operating Characteristic (ROC) curves are plotted for each ensemble model to visualize their performance in terms of true positive rate (sensitivity) and false positive rate.\n",
        "- The Area Under the ROC Curve (AUC) is calculated to quantify the model's discrimination ability between the positive and negative classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0nZiklkMDnV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Task 10: Represent the ROC of training and test results in the graphs\n",
        "# Calculate ROC curves for training set\n",
        "plt.figure(figsize=(8, 6))\n",
        "for clf, name in [(bagging_clf, 'Bagging'), (rf_clf, 'Random Forest'), (adaboost_clf, 'AdaBoost')]:\n",
        "    y_score = clf.predict_proba(X_test)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.5f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) - Training Set')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihg5KblV79XF"
      },
      "source": [
        "# Inference\n",
        "- Random Forest achieved the highest accuracy among the three ensemble models, with an accuracy of 97.08%.\n",
        "- Bagging and AdaBoost both achieved slightly lower accuracies, with Bagging at 95.32% and AdaBoost at 95.91%.\n",
        "- Despite the differences in accuracy, all three models demonstrated excellent performance, with AUC scores above 0.99.\n",
        "- Both Bagging and Random Forest models exhibited similar AUC scores, with Random Forest slightly outperforming Bagging by a small margin.\n",
        "- AdaBoost, while achieving a slightly lower accuracy compared to Random Forest, still showed a strong AUC score, indicating good discrimination between classes.\n",
        "- Overall, all three ensemble models performed well in diagnosing breast cancer, with Random Forest showing a slight advantage in accuracy and AUC.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}